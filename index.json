[{"content":"AI is becoming a more and more important topic in our daily lives, and understanding has stayed about the same. I\u0026rsquo;m here to fix that! One of the very interesting new types of AI are GANs. For this article I\u0026rsquo;ll be talking about one Stylegan2. Stylegan2 is a huge leap in image generation GANs. I know I am a bit behind on this whole shebang, but I just found out that I could run Stylegan2 myself, so I wanted to write about it!\nFirst, what even is a GAN? GAN stands for Generative Adversarial Network. A GAN is a set of two AIs that work together to create original content. GANs are made up of two neural nets, a generator and a discriminator. They are trained by feeding the training images to both the generator and the discriminator, the way you would usually train a NN. But then the fancy GAN-tech kicks in. The second phase of training is where the generator tries to generate images that the discriminator will classify as real, so that we can get the most realistic images possible. The discriminator also learns from its mistakes, making the whole model more effective as training time goes on. The good thing about this type of model is that it can be trained on some very complex data, such as audio, images, and even video!\n\u0026ldquo;Now, what about this Stylegan2 thingy-ma-bob?\u0026rdquo;, you may be asking. Well Stylegan2 is a GAN that has been optimized for images and even has some pre-trained models out there! One of the most impressive examples is the version trained on the FFHQ face dataset. It can generate images that are basically indistinguishable from normal photos of faces.\nFor example, can you determine which of these photos is real?\nIf you guessed the kid on the left is real, good job! You\u0026rsquo;re better at this than me! If you want to play this game, check out whichfaceisreal.com! The AI does have some telling features that can show an image is fake. Things that don\u0026rsquo;t really pertain to images of faces, or whatever dataset you have, such as logos and people in the background, tend to get messed up. Here are some examples I found of weird stuff that the site thispersondoesnotexist.com generated:\nAh yes, the Ḇ̸̨̢̨̼̟̰͈̞͍͈͓̼̫̞̒͂̒͛͌̌̓́͠͝ͅa̸̡̪̘̗̣͚̫̬͔͉̙͎̫̺̘̣͚̲͉͉̱͔̭͆̀́̃͘͜͠l̶̢̬͔͈̻̣̬̮͇̠̯̩̲̂͑̆̇̓̇̉̏̒͛̉̕͜͜͜t̵̨̡̧̛̙̬̬̫͎̱͔̺͕̩̳̪̳͔̟̖͓̪̲͇͉͍̀̓̐̈́̉̈̆̋͋̑̉͆̃̇͐͒͘i̸̔͗̍̐̓̅̔͌͛̊̅̆̏̾͌̚̚̕͝m̶̦̤̜͕̃̓̾̽̄̆̑̒͋͠a̵̛̰̰̽͆́̑̎̽̊͆̾́̇̅͊̇̇̑̚͘͘ṇ̴̜͉̽̏̋̅̐̃̋̈̓͆͗̽̾̀͌̋̆̓̇̎̑͗̚͘͝ ̷͌̈́̔͂̑̔̇̀̿̄̾̆̾̿͐̈́̚͠͝ are my favorite team.\nAnother fun thing that you can do with these really interesting AIs is watching them show how they think features evolve across multiple datapoints (those being images of faces). Here is a little video I generated with this Google Colab notebook (If you want to train your AI locally, instead of using a pretrained model, try this).\nA trippy interpollation\nAs you can see, at some points, it gets a bit confused, and it has some issues with people in the background. This is really interesting to watch, as we get a rare peek into the mind of a machine. Another really cool look into the minds of computers is the Aphantasia project. It uses a model called CLIP, that helps guide AIs using natural language and a GAN to generate those images. These images are gradually refined from random noise that was generated for the AI in the beginning. Here is a video of the AI generating an image based on the prompt \u0026ldquo;A woman walking her dog with her child\u0026rdquo; or something to that effect.\nAnoter interpolation\nTrippy, right? This is really a really interesting view into the way NNs, GANs, and other kinds of mechanical minds think! Fun experiments, and other interesting projects like this will be the best way to explain the ways that the computers that more an more control our lives work. Fun videos and websites like this can also be a very effective science communication method. Methods of explaining complex AI systems to laypeople will be very important in the coming years.\nPlease note: I am not an expert in this field, and am just presenting some thoughts I typed out during science class.\nSources:\n  https://arxiv.org/abs/1912.04958 ← Original Stylegan2 study!\n  https://medium.com/analytics-vidhya/gans-a-brief-introduction-to-generative-adversarial-networks-f06216c7200\n  https://towardsdatascience.com/stylegan2-ace6d3da405d\n  https://habr.com/en/post/537334/\n  ","permalink":"https://l3gacy.tk/posts/stylegan-machine-minds-and-scicoms/","summary":"AI is becoming a more and more important topic in our daily lives, and understanding has stayed about the same. I\u0026rsquo;m here to fix that! One of the very interesting new types of AI are GANs. For this article I\u0026rsquo;ll be talking about one Stylegan2. Stylegan2 is a huge leap in image generation GANs. I know I am a bit behind on this whole shebang, but I just found out that I could run Stylegan2 myself, so I wanted to write about it!","title":"Stylegan2, Machine Minds, \u0026 Science Communication"},{"content":"So, I finally got l3gacy.tk linked to the github pages! The process was a bit confusing, probably because I\u0026rsquo;ve never done something like this before, but here\u0026rsquo;s the steps I took.\nFirst I got a free domain from freenom.com. Quick tip, if you want one, write out the full domain in the domain search bar instead of just the first part (i.e. example.tk instead of just example). Once I had done that, I signed up for a free cloudflare acount, as they have a better domain-name-manegment-system-thing. Then I had to link my domain back to cloudflare, which was supprisingly easy. All I did was set the nameservers in freenom\u0026rsquo;s interface to the ones cloudflare gave me, and I was off to the races! (Well it took a couple hours, so maybe more of a road trip.)\nThe next step was getting that domain to point to my github pages. So I googled that, and I found a great [https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site](doc page) on how to set a custom domain in github pages (turns out there\u0026rsquo;s just a little textbox in the settings menu that adds a CNAME file). After that, it was a matter of adding some records to my domain in cloudflare, and it works now!\nThat\u0026rsquo;s all for today folks, stay safe and happy!\n- l3gacy\n","permalink":"https://l3gacy.tk/posts/domain-name-finaly/","summary":"So, I finally got l3gacy.tk linked to the github pages! The process was a bit confusing, probably because I\u0026rsquo;ve never done something like this before, but here\u0026rsquo;s the steps I took.\nFirst I got a free domain from freenom.com. Quick tip, if you want one, write out the full domain in the domain search bar instead of just the first part (i.e. example.tk instead of just example). Once I had done that, I signed up for a free cloudflare acount, as they have a better domain-name-manegment-system-thing.","title":"domain name, finaly"},{"content":"Hello! I\u0026rsquo;m Raleigh (he/they), (aka l3gacy, or l3gacyb3ta, or l3gacy.b3ta, etc\u0026hellip;), and this is my homepage! (Sounds like I\u0026rsquo;m on MySpace lol)\nMy blog is in the nav bar on top, and my contacts can be found under the contacts section in the nav bar.\nI\u0026rsquo;m very intrested in stuff like cybersecurity, cryptocurrencies, and musicals. I plan on going into a cybersecurity career at some point, so that\u0026rsquo;s probably gonna be a lot of that on here. I write code in python mostly, but I can also do c++ and I\u0026rsquo;m learning rust (It looks really cool!). I am a bit of a linux nerd, my laptop is currently quadruple-booting Gardua Linux, Ubuntu 21.04 beta, Arch Linux, and Windows (for school and games). My main IDE is vscode, and I sometimes do some vfx and 3d motion graphics stuff.\n","permalink":"https://l3gacy.tk/aboutme/","summary":"Hello! I\u0026rsquo;m Raleigh (he/they), (aka l3gacy, or l3gacyb3ta, or l3gacy.b3ta, etc\u0026hellip;), and this is my homepage! (Sounds like I\u0026rsquo;m on MySpace lol)\nMy blog is in the nav bar on top, and my contacts can be found under the contacts section in the nav bar.\nI\u0026rsquo;m very intrested in stuff like cybersecurity, cryptocurrencies, and musicals. I plan on going into a cybersecurity career at some point, so that\u0026rsquo;s probably gonna be a lot of that on here.","title":"about me"},{"content":"Well, this was a pain in the butt.\nI didn\u0026rsquo;t feel like messing with github actions again, as I hate that thing with a passion. So I was looking through the hexo docs and I found a usefull one-command deploy option. All you have to do is add this little tidbit to your _config.yaml.\n deploy: type: git repo: https://github.com/\u0026lt;username\u0026gt;/\u0026lt;project\u0026gt; # example, https://github.com/l3gacyb3ta/l3gacyb3ta.github.io branch: \u0026lt;whatever branch you use\u0026gt; You also have to install hexo-deployer-git, which is simple, just use this:\n$ npm install hexo-deployer-git --save\nAnd then all you have to do to deploy is:\n$ hexo deploy\nThat was easy!\n","permalink":"https://l3gacy.tk/posts/got-this-working-on-github-pages/","summary":"Well, this was a pain in the butt.\nI didn\u0026rsquo;t feel like messing with github actions again, as I hate that thing with a passion. So I was looking through the hexo docs and I found a usefull one-command deploy option. All you have to do is add this little tidbit to your _config.yaml.\n deploy: type: git repo: https://github.com/\u0026lt;username\u0026gt;/\u0026lt;project\u0026gt; # example, https://github.com/l3gacyb3ta/l3gacyb3ta.github.io branch: \u0026lt;whatever branch you use\u0026gt; You also have to install hexo-deployer-git, which is simple, just use this:","title":"Got this working on github pages!"},{"content":"So a while back I was asked by my dad, \u0026ldquo;What does BitCoin have to do with these computer parts shortages?\u0026quot; Well I knew the basics of the blockchain idea, but I didn't know the specifics. So after a bit of googling I found out and that was that. Now a few days later I saw a video in my YouTube recommended feed: \u0026ldquo;Programming the blockchain with Ethereum!\u0026rdquo; or something like that. I then watched it and got sucked into a rabbit hole.\nAfter I had fallen through that, I wanted to make a smart contract. So the first thing I did was\u0026hellip; copy an ERC20 token's code. (Life of a developer lol) That got me into tokens, so I found Uniswap and I was like \u0026ldquo;I wanna make something cool and social on the blockchain! Like Uniswap!\u0026quot; So I started writing a little app to help with situations like paying a bill together with friends.\nWhile I was writing the code for it at school (after I had done my work, don't worry), one of my friends was looking over my shoulder and asked me what I was doing. So I explained and she really wanted to draw an icon for it, so Marshy, the bill splitting dapp, was born! (The icon is a marshmellow, fyi)\nThe code I've written is on my GitHub, and y'all are free to contribute! I'm gonna learn React to make a cool web interface using web3.js. If anyone has any tips, please contact me on my contacts page.\nCode Breakdown: // SPDX-License-Identifier: UNLICENSED pragma solidity \u0026gt;=0.7.0 \u0026lt;0.8.0; contract MarshyShare { // The owner, for refund of extra eth. address payable private owner; // Current eth locked up in the contract int256 balance; // The goal of the contract, once this is reached, it will pay out. int256 goal; // The address the goal should be payed out to. address payable payee;  The first bit of the code sets up the smart-contract, and gives it some properties, such as an owner, a payee, a balance, and a goal. The addresses have to be 'payable' so that we can transfer ether to them in the future.\n// event for EVM logging event OwnerSet(address indexed oldOwner, address indexed newOwner); event GoalFulfilled();  This sets up a bit of logging, most of which I haven't implemented yet \\xf0\\x9f\\x98\\x85.\n // modifier to check if caller is owner modifier isOwner() { // If the first argument of \\'require\\' evaluates to \\'false\\', execution terminates and all // changes to the state and to Ether balances are reverted. // This used to consume all gas in old EVM versions, but not anymore. // It is often a good idea to use \\'require\\' to check if functions are called correctly. // As a second argument, you can also provide an explanation about what went wrong. require(msg.sender == owner, \u0026quot;Caller is not owner\u0026quot;); _; }  This sets up an important 'modifier', which can run before functions, to make sure certain functions can only be called by the owner. Nothing uses this yet, but it will come up in future Marshy versions.\n function deposit() public payable { // adds to balance and subracts from goal balance = balance + int(msg.value); goal = goal - int(msg.value); // If the goal is met if(goal \u0026lt;= 0) { // Pay the payee payee.transfer(uint(goal)); // Set the new balance balance = balance - goal; // logging! emit GoalFulfilled(); // transfer extra eth, if the balance is positive (should be) if(balance \u0026gt; 0){ owner.transfer(uint(balance)); } } }  This is the big fancy deposit function! What it does is that, when ether is received, it does some math to see if the goal is met, and then pays everyone out.\n // Pretty easy, just get the balance function getBalance() public view returns(int256 balance) {return balance;} // Same as above, but with the current goal function getGoal() public view returns(int256 _goal) {return goal;}  These two are mostly for the web dapp I have planned, so that you can get balances and the such.\n // Fallback deposit functions fallback() external payable {balance = balance + int(msg.value);} receive() external payable {balance = balance + int(msg.value);} }  This is the end, and it just makes sure any accidental transfers get logged in the balance, it doesn't yet interact with the goal or the payout logic yet, so that's for an update down the line.\nThe full code is below, and on my GitHub. Feel free to use it, it doesn't have a license.\n// SPDX-License-Identifier: UNLICENSED pragma solidity \u0026gt;=0.7.0 \u0026lt;0.8.0; contract MarshyShare { // The owner, for refund of extra eth. address payable private owner; // Current eth locked up in the contract int256 balance; // The goal of the contract, once this is reached, it will pay out. int256 goal; // The address the goal should be payed out to. address payable payee; // event for EVM logging event OwnerSet(address indexed oldOwner, address indexed newOwner); event GoalFulfilled(); // modifier to check if caller is owner modifier isOwner() { // If the first argument of \\'require\\' evaluates to \\'false\\', execution terminates and all // changes to the state and to Ether balances are reverted. // This used to consume all gas in old EVM versions, but not anymore. // It is often a good idea to use \\'require\\' to check if functions are called correctly. // As a second argument, you can also provide an explanation about what went wrong. require(msg.sender == owner, \u0026quot;Caller is not owner\u0026quot;); _; } constructor(int256 toBePayed, address payable _payee) { // Set balance to 0 balance = 0; // The owner is the sender and the payee is the _payee argument owner = msg.sender; payee = _payee; // setup goal goal = toBePayed; } function deposit() public payable { // adds to balance and subracts from goal balance = balance + int(msg.value); goal = goal - int(msg.value); // If the goal is met if(goal \u0026lt;= 0) { // Pay the payee payee.transfer(uint(goal)); // Set the new balance balance = balance - goal; // logging! emit GoalFulfilled(); // transfer extra eth, if the balance is positive (should be) if(balance \u0026gt; 0){ owner.transfer(uint(balance)); } } } // Pretty easy, just get the balance function getBalance() public view returns(int256 balance) {return balance;} // Same as above, but with the current goal function getGoal() public view returns(int256 _goal) {return goal;} // Fallback deposit functions fallback() external payable {balance = balance + int(msg.value);} receive() external payable {balance = balance + int(msg.value);} } ","permalink":"https://l3gacy.tk/posts/ethereummarshyanewproject/","summary":"So a while back I was asked by my dad, \u0026ldquo;What does BitCoin have to do with these computer parts shortages?\u0026quot; Well I knew the basics of the blockchain idea, but I didn't know the specifics. So after a bit of googling I found out and that was that. Now a few days later I saw a video in my YouTube recommended feed: \u0026ldquo;Programming the blockchain with Ethereum!\u0026rdquo; or something like that.","title":"ethereum \u0026 marshy, a new project!"},{"content":"~Soo~ today we have something a tad bit more complicated, so first I'll introduce a few concepts and tools:\n1\\. Markov chains: From simple.wikipedia.org: \u0026ldquo;A Markov chain is a model of some random process that happens over time. Markov chains are called that because they follow a rule called the Markov property. The Markov property says that whatever happens next in a process only depends on how it is right now (the state). It doesn't have a \u0026ldquo;memory\u0026rdquo; of how it was before. It is helpful to think of a Markov chain as evolving through discrete steps in time, although the \u0026ldquo;step\u0026rdquo; doesn't need to have anything to do with time.\u0026rdquo;\n2\\. Jupyter notebooks: Jupyter notebooks are a way of sharing code, usually, academic and running it in a presentable and browser-friendly format. I'm gonna share my code in Google's free notebook hosting service, collaboratory.\nNow, usually, Markov chains are used to generate text, as seen here, and here. But, I've done something weird. I've generated images.\n\u0026ldquo;Well l3gacy, how does this work?\u0026rdquo; - You, now, probably. It's pretty easy actually!\nFirst I take in 3 training images (I know that's not a lot, any more and it took hours to run), here I chose 3 pieces of Bauhaus art. These are then converted into a list of the RGB values in the images. This is then fed into the Markov chain algorithm. Usually, it expects the list input to be a list of words, but here I fed the RGB values. It then does its Markov-magic and spits out an output image.\nRight now, the output is in the form of a list of RGB pixels as a string, so we convert it back, turn it into an image, and show it!\nBam! Machine-generated images!\nNow, this is interesting. We can tell from the way there are horizontal lines, the way that this algorithm is supposed to work, as it usually would write words from left to right.\nIf y'all wanna play around with the code, here's a google collab link\nThat's it! Thanks and goodbye.\n\\-l3gacy\n","permalink":"https://l3gacy.tk/posts/imagesmadebywritingbots/","summary":"~Soo~ today we have something a tad bit more complicated, so first I'll introduce a few concepts and tools:\n1\\. Markov chains: From simple.wikipedia.org: \u0026ldquo;A Markov chain is a model of some random process that happens over time. Markov chains are called that because they follow a rule called the Markov property. The Markov property says that whatever happens next in a process only depends on how it is right now (the state).","title":"images made by writing bots?"},{"content":"The Windows 10 search is slow and resource intensive. So I decided to build a new one!\nThe new search engine uses a flask-sqlite backend, using a jinja html front end.\nIt first indexes both of the drives and parses their files into the databases in a custom format\nThen the front-end does a SQL query on the database to find the files. After that the custom jinja templates do a HTML \u0026ldquo;render\u0026rdquo; with the data from the query and send it to you!\nAn interesting feature is the \u0026ldquo;open\u0026rdquo; function that executes a \u0026ldquo;start\u0026rdquo; command on the host machine, which then open the files.\n","permalink":"https://l3gacy.tk/posts/bettersearchforwindows/","summary":"The Windows 10 search is slow and resource intensive. So I decided to build a new one!\nThe new search engine uses a flask-sqlite backend, using a jinja html front end.\nIt first indexes both of the drives and parses their files into the databases in a custom format\nThen the front-end does a SQL query on the database to find the files. After that the custom jinja templates do a HTML \u0026ldquo;render\u0026rdquo; with the data from the query and send it to you!","title":"better search for windows"},{"content":"There\u0026rsquo;s not much here yet! But soon there will be!\nTo check out the source code for this whole shebang, look for the blog repo in my GitHub! The link is in contacts.\n-l3gacy\nUpdate: Old blog posts are now in!\n","permalink":"https://l3gacy.tk/posts/welcome/","summary":"There\u0026rsquo;s not much here yet! But soon there will be!\nTo check out the source code for this whole shebang, look for the blog repo in my GitHub! The link is in contacts.\n-l3gacy\nUpdate: Old blog posts are now in!","title":"Welcome!"},{"content":"You may be thinking \u0026ldquo;Why is OS X so intresting?\u0026rdquo; Well this is intresting because it's running by a VM!\nFirstly, you may be asking yourselves \u0026ldquo;Why would you do this?\u0026rdquo; or \u0026ldquo;What is the point of this?\u0026rdquo;.\nThe point is, I can, so why not\\xe2\\x80\\xbd\nMoving on, how?\nFirst, I installed the \u0026ldquo;Update to Catalina\u0026rdquo; app on my dad's MacBook Pro. I then followed a guide to transform this app into an .iso image.\nThen, I installed VirtualBox, and an expansion for it, to allow me to edit some characteristics of the VMs.\nI tricked the VM into thinking it was an iMac, and then installed OS X Catalina onto it.\nI then spent a while messing around with drivers to get internet bridging up.\nOnce that was working, I updated to Big Sur. That was supprisingly easy!\n","permalink":"https://l3gacy.tk/posts/macosxinavm/","summary":"You may be thinking \u0026ldquo;Why is OS X so intresting?\u0026rdquo; Well this is intresting because it's running by a VM!\nFirstly, you may be asking yourselves \u0026ldquo;Why would you do this?\u0026rdquo; or \u0026ldquo;What is the point of this?\u0026rdquo;.\nThe point is, I can, so why not\\xe2\\x80\\xbd\nMoving on, how?\nFirst, I installed the \u0026ldquo;Update to Catalina\u0026rdquo; app on my dad's MacBook Pro. I then followed a guide to transform this app into an .","title":"mac OS X .... in a VM‽"},{"content":"First render: The idea for this was a volleyball scene on a beach island.\nThis was rendered in TV PAL 16:9.\n\n Click to view\n DO THIS FOR OTHER VIDEOS\nSecond render: Textures were reset for this one so I could fix the animation on this.\nThis was rendered in TV PAL 16:9.\n\nFinal render: What I changed here was I added textures to everything,\nchanged the plane on the bottom to several squares, and added a skybox + water.\nThis was rendered in HDTV 1080p.\n\n","permalink":"https://l3gacy.tk/posts/beach/","summary":"First render: The idea for this was a volleyball scene on a beach island.\nThis was rendered in TV PAL 16:9.\n\n Click to view\n DO THIS FOR OTHER VIDEOS\nSecond render: Textures were reset for this one so I could fix the animation on this.\nThis was rendered in TV PAL 16:9.\n\nFinal render: What I changed here was I added textures to everything,\nchanged the plane on the bottom to several squares, and added a skybox + water.","title":"beach"},{"content":"  I tracked approx 20 points in the image.\n  I extrapolated the movement of the camera.\n  I modeled the window and added the macbook and the drawers.\n  Then I exported to a set of 360 images and recombined them into a video.\n  That\u0026rsquo;s my youtube channel, btw\n","permalink":"https://l3gacy.tk/posts/motiontracking/","summary":"I tracked approx 20 points in the image.\n  I extrapolated the movement of the camera.\n  I modeled the window and added the macbook and the drawers.\n  Then I exported to a set of 360 images and recombined them into a video.\n  That\u0026rsquo;s my youtube channel, btw","title":"motion tracking"},{"content":"V1.0 Walk cycle animation done based on traditonal walk cycle animation.\n","permalink":"https://l3gacy.tk/posts/riggingnottheelection/","summary":"V1.0 Walk cycle animation done based on traditonal walk cycle animation.","title":"rigging, not the election"},{"content":"  First I modeled the Treadripper CPU from AMD.\n  Then, I used rigidbody physics to simulate them bouncing away.\n  I used Windows Video Editor to sync the audio of the music I stiched together to the AMD text.\n  Finally I used Shotcut to edit all videos together.\n  ","permalink":"https://l3gacy.tk/posts/threadripperad/","summary":"  First I modeled the Treadripper CPU from AMD.\n  Then, I used rigidbody physics to simulate them bouncing away.\n  I used Windows Video Editor to sync the audio of the music I stiched together to the AMD text.\n  Finally I used Shotcut to edit all videos together.\n  ","title":"threadripper ad"}]